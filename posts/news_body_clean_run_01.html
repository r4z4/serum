
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Newsgroup 20 Dataset with Body - Clean Run 01 - r4z4 Site</title>
    <link rel="stylesheet" href="/serum/assets/css/style.css">
    <link rel="stylesheet" href="/serum/assets/css/home_animation.css">
    <link rel="stylesheet" href="/serum/assets/css/markdown.css">
  </head>
  <body>
    
<div id="navbar_div">
  <ul id="navbar">
    <li><a href="/serum/index.html">Home</a></li>
    <li><a href="/serum/posts">Posts</a></li>
  </ul>
</div>

    <h1 class="base-header"><a href="/serum/">Various Writings and Observations</a></h1>
    <section class="md-body"><h1 id="newsgroup-20-dataset-with-body---clean-run-01">Newsgroup 20 Dataset with Body - Clean Run 01</h1><p>Posted on Wednesday, 16 Aug 2023 by r4z4</p><p>Tags:</p><ul><li><a href="/serum/tags/NLP">NLP</a></li><li><a href="/serum/tags/news">news</a></li></ul><p>After seeing some pretty lackluster results from the subject only dataset, lets now go ahead and use the body for the text that we will train on. This should offer us a lot more data, but it was a struggle wrangling it all into the dataframes. I chose to go ahead and start from the text files themselves, and I will incode some snippets of the transformations below.</p><hr class="thin"/><pre><code class="python">import numpy as np
import regex as re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
sys.path.insert(1, os.path.join(sys.path[0], &#39;..&#39;))
import utils

import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences</code></pre><pre><code class="python">import os
dirpath = &#39;../data/clean_pkl/to_use/&#39;
directory = os.fsencode(dirpath)
df = pd.DataFrame(columns=[&#39;newsgroup&#39;, &#39;body&#39;])
for file in os.listdir(directory):
     filename = os.fsdecode(file)
     name, ext = filename.split(&#39;.&#39;)
     if filename.endswith(&quot;.pkl&quot;): 
         df_ = pd.read_pickle(dirpath + filename) 
         df = pd.merge(
            df, df_, how=&quot;outer&quot;
        )
         continue
     else:
         continue</code></pre><pre><code class="python">df.shape</code></pre><pre><code>(40590, 2)</code></pre><pre><code class="python">df = pd.read_pickle(&#39;../data/dataframes/newsgroup_body_cleaned.pkl&#39;)</code></pre><pre><code class="python">from IPython.display import display, HTML
display(HTML(&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;))
print(df.sample(frac=1).reset_index(drop=True).loc[:,[&#39;newsgroup&#39;, &#39;body&#39;]].head().to_markdown())</code></pre><table><thead><tr><th style="text-align: right"></th><th style="text-align: left">newsgroup</th><th style="text-align: left">body</th></tr></thead><tbody><tr><td style="text-align: right">0</td><td style="text-align: left">religion</td><td style="text-align: left">deuterocanon esp sirach poram ihlpbattcom wrote let talk principl accept god set standard ought includ scriptur - ask  authorit authorit qu</td></tr><tr><td style="text-align: right">1</td><td style="text-align: left">sport</td><td style="text-align: left">oiler rumour - team move press confer next week heard stori local sport news broadcast edmonton oiler owner peter pocklington hold press co</td></tr><tr><td style="text-align: right">2</td><td style="text-align: left">politics</td><td style="text-align: left">ban firearm articl apr gnvifasufledu jrm gnvifasufledu write alcohol ban today would much difficult manag large-scal smuggl oper cop rank</td></tr><tr><td style="text-align: right">3</td><td style="text-align: left">seller</td><td style="text-align: left">scan radio realist pro—wa  sell  articl  altradioscann path usenetinscwruedu clevelandfreenetedu aj newsgroup altradioscann realist pro- s</td></tr><tr><td style="text-align: right">4</td><td style="text-align: left">comp_elec</td><td style="text-align: left">help object appear thrice hey got equat editor sinc nt automag appear object dialog box ie insert — object — equat decid manual place we</td></tr></tbody></table><pre><code class="python">df.shape</code></pre><pre><code>(35790, 2)</code></pre><pre><code class="python">from itertools import islice
def chunk(it, size):
    it = iter(it)
    return iter(lambda: tuple(islice(it, size)), ())

# This will output lists of words, at most 100 each
def long_split(s):
    if len(s) &gt; 100:
        tuple_list = list(chunk(s.split(), 100))
        return [&#39; &#39;.join(tups) for tups in tuple_list]
    </code></pre><pre><code class="python">df[&#39;exploded_body&#39;] = df[&#39;body&#39;].apply(lambda x: long_split(x))
</code></pre><pre><code class="python">df[&#39;exploded_body&#39;][3]</code></pre><pre><code>[&#39;analges diuret sometim see otc prepar muscl achesback ach combin aspirin diuret 
idea seem reduc inflamm get rid fluid doe thi actual work thank -larri c&#39;]</code></pre><pre><code class="python">df = df.explode(&#39;exploded_body&#39;)</code></pre><pre><code class="python">df.shape</code></pre><pre><code>(72250, 3)</code></pre><h2 id="recheck-our-corpus">Recheck our corpus</h2><p>I am still trying get a better sense of what is happening here in the explode function to cause is to get None in the exploded_body col. In cases like this when I just always like to make sure I look over the data to make sure it is still correct. We’ll eventually find out when we get our eval metrics but it is pretty clean if you just sample a few rows and make sure you don’t have Wayne Gretzky articles under religion.  He was good though.</p><pre><code class="python">from IPython.display import display, HTML
display(HTML(&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;))
print(df[df[&#39;exploded_body&#39;].apply(lambda x: not isinstance(x, str))].to_markdown())</code></pre><table><thead><tr><th style="text-align: right"></th><th style="text-align: left">newsgroup</th><th style="text-align: left">body</th><th style="text-align: left">exploded_body</th></tr></thead><tbody><tr><td style="text-align: right">41</td><td style="text-align: left">sci_med</td><td style="text-align: left">twitch eye thi one time attribut lack sleep sinc disappear night good zzz</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">56</td><td style="text-align: left">sci_med</td><td style="text-align: left">open letter hillari rodham clinton  post one repli letter -km</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">127</td><td style="text-align: left">sci_med</td><td style="text-align: left">erythromycin erythromycin effect treat pneumonia -fm</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">285</td><td style="text-align: left">sci_med</td><td style="text-align: left">foreskin troubl done short circumcis adult male whose foreskin retract</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">3125</td><td style="text-align: left">sci_med</td><td style="text-align: left">sixty-two thousand wa mani read</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">3138</td><td style="text-align: left">sci_med</td><td style="text-align: left">read</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">3142</td><td style="text-align: left">sci_med</td><td style="text-align: left">mani read</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">3207</td><td style="text-align: left">sci_med</td><td style="text-align: left">sixty-two thousand wa mani read</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">20992</td><td style="text-align: left">religion</td><td style="text-align: left">daili vers whoever listen live safeti eas without fear harm proverb</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">21066</td><td style="text-align: left">religion</td><td style="text-align: left">daili vers keep perfect peac whose mind steadfast becaus trust isaiah</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">21089</td><td style="text-align: left">religion</td><td style="text-align: left">daili vers dishonest money dwindl away gather money littl littl make grow proverb</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">21101</td><td style="text-align: left">religion</td><td style="text-align: left">daili vers purifi yourselv obey truth sincer love brother love one anoth deepli heart ipet</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">24860</td><td style="text-align: left">autos</td><td style="text-align: left">invert fork need</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">24873</td><td style="text-align: left">autos</td><td style="text-align: left">help bike short sure older bike yamaha virago  ha spec seat height  honda shadow</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">24933</td><td style="text-align: left">autos</td><td style="text-align: left">protect gear second boot oil spot car particularli slipperi park bike good boot help well — squid</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">24946</td><td style="text-align: left">autos</td><td style="text-align: left">xs time could kind soul tell advanc timingrev  xs special bought canada thank</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">24993</td><td style="text-align: left">autos</td><td style="text-align: left">use bike east vs west coast hpcc</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">25011</td><td style="text-align: left">autos</td><td style="text-align: left">want advic new cylist angel levin write exactli danger look anyon particular mind jodi -</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">25043</td><td style="text-align: left">autos</td><td style="text-align: left">dog articl apr acsucalgaryca parr acsucalgaryca charl parr write newsgroup</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">38685</td><td style="text-align: left">comp_elec</td><td style="text-align: left">booksinfo audio dsp</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">38690</td><td style="text-align: left">comp_elec</td><td style="text-align: left">self-modifi hardwar permit quot fragment praetzel suneeuwaterlooca articl context -newsgroup</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">38693</td><td style="text-align: left">comp_elec</td><td style="text-align: left">radar detector detector detect oscil oper detector saw stori use canada nt go put oscil car -</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">38704</td><td style="text-align: left">comp_elec</td><td style="text-align: left">video io idea anyon idea build cheap low resolut high - video projector exampl lcd slide projector</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">40495</td><td style="text-align: left">comp_elec</td><td style="text-align: left">doe ani one know biggest rom present pleas replay yxy usledu thank lot</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">40526</td><td style="text-align: left">comp_elec</td><td style="text-align: left">card phone help understand cardphon oper valu store phonecard thanx</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">40531</td><td style="text-align: left">comp_elec</td><td style="text-align: left">hd-tv sound system would like get inform current system use hd-tv sound systemsthank</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">40548</td><td style="text-align: left">comp_elec</td><td style="text-align: left">whi circuit board green</td><td style="text-align: left"></td></tr></tbody></table><pre><code class="python">df.iloc[39]</code></pre><pre><code>newsgroup                                                  sci_med
body             mysteri ill eye problem friend ha follow sympt...
exploded_body    mysteri ill eye problem friend ha follow sympt...
Name: 27, dtype: object</code></pre><pre><code class="python">df.iloc[40]</code></pre><pre><code>newsgroup                                                  sci_med
body             mysteri ill eye problem friend ha follow sympt...
exploded_body    acut quit concern becaus retin hemorrhag becom...
Name: 27, dtype: object</code></pre><pre><code class="python">df.iloc[42]</code></pre><pre><code>newsgroup                                                  sci_med
body             new diet -- work great articl apr inmetcambinm...
exploded_body    recent version adipos problem anecdot report i...
Name: 28, dtype: object</code></pre><pre><code class="python">bad_indices = df[df[&#39;exploded_body&#39;].apply(lambda x: not isinstance(x, str))].index</code></pre><pre><code class="python">df.drop(bad_indices, inplace = True)</code></pre><pre><code class="python">df.shape</code></pre><pre><code>(69177, 3)</code></pre><pre><code class="python">df.to_pickle(&#39;../data/dataframes/newsgroup_body_cleaned_exploded.pkl&#39;)</code></pre><pre><code class="python">all_categories = [&#39;sport&#39;, &#39;autos&#39;, &#39;religion&#39;, &#39;comp_elec&#39;, &#39;sci_med&#39;, &#39;seller&#39;, &#39;politics&#39;]
# We&#39;ll use all
target_categories = [&#39;sport&#39;, &#39;autos&#39;, &#39;religion&#39;, &#39;comp_elec&#39;, &#39;sci_med&#39;, &#39;seller&#39;, &#39;politics&#39;]</code></pre><pre><code class="python"># container for sentences
X = np.array([t for t in df[&#39;exploded_body&#39;]])
# container for sentences
y = np.array([n for n in df[&#39;newsgroup&#39;]])</code></pre><pre><code class="python">encoder = LabelEncoder()
y = encoder.fit_transform(df[&#39;newsgroup&#39;])</code></pre><pre><code class="python">y.shape</code></pre><pre><code>(69177,)</code></pre><pre><code class="python">from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    stratify=y, 
                                                    test_size=0.25)

classes = np.unique(y_train)
mapping = dict(zip(classes, target_categories))

len(X_train), len(X_test), classes, mapping</code></pre><pre><code>(51882,
 17295,
 array([0, 1, 2, 3, 4, 5, 6]),
 {0: &#39;sport&#39;,
  1: &#39;autos&#39;,
  2: &#39;religion&#39;,
  3: &#39;comp_elec&#39;,
  4: &#39;sci_med&#39;,
  5: &#39;seller&#39;,
  6: &#39;politics&#39;})</code></pre><pre><code class="python"># model parameters
vocab_size = 1200
embedding_dim = 16
max_length = 120
trunc_type=&#39;post&#39;
padding_type=&#39;post&#39;
oov_tok = &quot;&lt;OOV&gt;&quot;</code></pre><pre><code class="python"># tokenize sentences
tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(X_train)
word_index = tokenizer.word_index

# convert train dataset to sequence and pad sequences
train_sequences = tokenizer.texts_to_sequences(X_train)
train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)

# convert validation dataset to sequence and pad sequences
validation_sequences = tokenizer.texts_to_sequences(X_test)
validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length)</code></pre><pre><code class="python">### Final layer must be same as y.shape output -&gt; # categories</code></pre><pre><code class="python"># model initialization
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation=&#39;relu&#39;),
    tf.keras.layers.Dense(7, activation=&#39;sigmoid&#39;)
])
model._name = &quot;NewsgroupBodyCleanBOW&quot;
# compile model
# categorical-cross-entropy requires labels one-hot-encoded. sparse = as ints. binary = t/f
model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])

# model summary
print(model.summary())</code></pre><pre><code>Model: &quot;NewsgroupBodyCleanBOW&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding_1 (Embedding)     (None, 120, 16)           19200     

 global_average_pooling1d_1   (None, 16)               0         
 (GlobalAveragePooling1D)                                        

 dense_2 (Dense)             (None, 24)                408       

 dense_3 (Dense)             (None, 7)                 175       

=================================================================
Total params: 19,783
Trainable params: 19,783
Non-trainable params: 0
_________________________________________________________________
None</code></pre><pre><code class="python"># fit model
num_epochs = 20
history = model.fit(train_padded, y_train, 
                    epochs=num_epochs, verbose=1,
                    validation_split=0.3)

# predict values
pred = model.predict(validation_padded)</code></pre><pre><code>Epoch 1/20
1135/1135 [==============================] - 5s 3ms/step - loss: 1.3570 - accuracy: 0.4956 - val_loss: 0.9589 - val_accuracy: 0.6743
Epoch 2/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.7806 - accuracy: 0.7425 - val_loss: 0.6945 - val_accuracy: 0.7727
Epoch 3/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.6152 - accuracy: 0.8015 - val_loss: 0.5928 - val_accuracy: 0.8094
Epoch 4/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.5274 - accuracy: 0.8303 - val_loss: 0.5361 - val_accuracy: 0.8285
Epoch 5/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.4730 - accuracy: 0.8470 - val_loss: 0.4974 - val_accuracy: 0.8406
Epoch 6/20
1135/1135 [==============================] - 4s 4ms/step - loss: 0.4379 - accuracy: 0.8571 - val_loss: 0.4825 - val_accuracy: 0.8468
Epoch 7/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.4147 - accuracy: 0.8647 - val_loss: 0.4677 - val_accuracy: 0.8490
Epoch 8/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3959 - accuracy: 0.8697 - val_loss: 0.4553 - val_accuracy: 0.8510
Epoch 9/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3811 - accuracy: 0.8736 - val_loss: 0.4470 - val_accuracy: 0.8536
Epoch 10/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.8787 - val_loss: 0.4403 - val_accuracy: 0.8563
Epoch 11/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3581 - accuracy: 0.8806 - val_loss: 0.4384 - val_accuracy: 0.8545
Epoch 12/20
1135/1135 [==============================] - 4s 4ms/step - loss: 0.3484 - accuracy: 0.8850 - val_loss: 0.4363 - val_accuracy: 0.8566
Epoch 13/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3399 - accuracy: 0.8865 - val_loss: 0.4303 - val_accuracy: 0.8583
Epoch 14/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3325 - accuracy: 0.8889 - val_loss: 0.4267 - val_accuracy: 0.8605
Epoch 15/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3253 - accuracy: 0.8917 - val_loss: 0.4265 - val_accuracy: 0.8649
Epoch 16/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3197 - accuracy: 0.8935 - val_loss: 0.4240 - val_accuracy: 0.8630
Epoch 17/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3133 - accuracy: 0.8960 - val_loss: 0.4225 - val_accuracy: 0.8639
Epoch 18/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3081 - accuracy: 0.8981 - val_loss: 0.4207 - val_accuracy: 0.8659
Epoch 19/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.3029 - accuracy: 0.9004 - val_loss: 0.4205 - val_accuracy: 0.8666
Epoch 20/20
1135/1135 [==============================] - 4s 3ms/step - loss: 0.2981 - accuracy: 0.9015 - val_loss: 0.4228 - val_accuracy: 0.8671
541/541 [==============================] - 1s 2ms/step</code></pre><pre><code class="python">import os

file_name = &#39;run_01&#39;
plot_type = &#39;history&#39;
model_name = &#39;newsgroup_body_clean&#39;
#####
os.makedirs(f&quot;images/{plot_type}&quot;, exist_ok=True)
os.makedirs(f&quot;images/{plot_type}/{model_name}&quot;, exist_ok=True)
save_path = f&#39;images/{plot_type}/{model_name}/{file_name}.png&#39; 

utils.plot_history_and_save(history, save_path)</code></pre><p><img src="/assets/images/news/body_clean_run_01.png" alt="png"/></p><pre><code class="python"># TensorFlow SavedModel format =&gt; .keras
model_file = &#39;models/newsgroup_body_clean_model&#39;
model.save(model_file)</code></pre><p>That just warms me up a bit. Now, lets take a look at what some augmentation can do. I am not expecting too much of a change here to be honest, and am actually curious if we will experience any setbacks and what some of the initial runs are like in the epochs.</p></section>
  </body>
</html>
