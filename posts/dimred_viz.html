
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Dimensionality Reduction & Visualization - r4z4 Site</title>
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/home_animation.css">
    <link rel="stylesheet" href="/assets/css/markdown.css">
  </head>
  <body>
    
<div id="navbar_div">
  <ul id="navbar">
    <li><a href="/index.html">Home</a></li>
    <li><a href="/posts">Posts</a></li>
  </ul>
</div>

    <h1 class="base-header"><a href="/">Various Writings and Observations</a></h1>
    <section class="md-body"><h1 id="dimensionality-reduction-&amp;-visualization">Dimensionality Reduction &amp; Visualization</h1><p>Posted on Wednesday, 16 Aug 2023 by r4z4</p><p>Tags:</p><ul><li><a href="/tags/dimensionality">dimensionality</a></li><li><a href="/tags/news">news</a></li><li><a href="/tags/visualization">visualization</a></li></ul><pre><code class="python">import numpy as np
from scipy import spatial
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE</code></pre><hr class="thin"/><p>The <a href="https://radimrehurek.com/gensim/">Gemsim</a> library is a pretty common one to see in many of the NLP tutorials out there. For many of the tasks that we can do with these limited datasets it is likely an overreach, but it does provide some really nice packages and functions to visualizing embeddings. Two of the more common approaches are via t-SNE and PCA.</p><hr class="thin"/><pre><code class="python">import pickle
from gensim.test.utils import datapath, get_tmpfile
from gensim.models import KeyedVectors
from gensim.scripts.glove2word2vec import glove2word2vec


glove_file = &#39;./glove.6B.50d.txt&#39;
word2vec_glove_file = get_tmpfile(&quot;glove.6B.50d.word2vec.txt&quot;)
glove2word2vec(glove_file, word2vec_glove_file)

model = KeyedVectors.load_word2vec_format(word2vec_glove_file)

filename = &#39;glove2word2vec_model.sav&#39;
pickle.dump(model, open(filename, &#39;wb&#39;))</code></pre><pre><code class="python">filename = &#39;glove2word2vec_model.sav&#39;
model = pickle.load(open(filename, &#39;rb&#39;))

def append_list(sim_words, words):
    
    list_of_words = []
    
    for i in range(len(sim_words)):
        
        sim_words_list = list(sim_words[i])
        sim_words_list.append(words)
        sim_words_tuple = tuple(sim_words_list)
        list_of_words.append(sim_words_tuple)
        
    return list_of_words

input_word = &#39;school,apple,toilet&#39;
user_input = [x.strip() for x in input_word.split(&#39;,&#39;)]
result_word = []
    
for words in user_input:
    
        sim_words = model.most_similar(words, topn = 5)
        sim_words = append_list(sim_words, words)
            
        result_word.extend(sim_words)
    
similar_word = [word[0] for word in result_word]
similarity = [word[1] for word in result_word] 
similar_word.extend(user_input)
labels = [word[2] for word in result_word]
label_dict = dict([(y,x+1) for x,y in enumerate(set(labels))])
color_map = [label_dict[x] for x in labels]</code></pre><pre><code class="python">import plotly
import numpy as np
import plotly.graph_objs as go
from sklearn.decomposition import PCA

def display_pca_scatterplot_3D(model, user_input=None, words=None, label=None, color_map=None, topn=5, sample=10):

    if words == None:
        if sample &gt; 0:
            words = np.random.choice(list(model.vocab.keys()), sample)
        else:
            words = [ word for word in model.vocab ]
    
    word_vectors = np.array([model[w] for w in words])
    
    three_dim = PCA(random_state=0).fit_transform(word_vectors)[:,:3]
    # For 2D, change the three_dim variable into something like two_dim like the following:
    # two_dim = PCA(random_state=0).fit_transform(word_vectors)[:,:2]

    data = []
    count = 0
    
    for i in range (len(user_input)):

                trace = go.Scatter3d(
                    x = three_dim[count:count+topn,0], 
                    y = three_dim[count:count+topn,1],  
                    z = three_dim[count:count+topn,2],
                    text = words[count:count+topn],
                    name = user_input[i],
                    textposition = &quot;top center&quot;,
                    textfont_size = 20,
                    mode = &#39;markers+text&#39;,
                    marker = {
                        &#39;size&#39;: 10,
                        &#39;opacity&#39;: 0.8,
                        &#39;color&#39;: 2
                    }
       
                )
                
                # For 2D, instead of using go.Scatter3d, we need to use go.Scatter and delete the z variable. Also, instead of using
                # variable three_dim, use the variable that we have declared earlier (e.g two_dim)
            
                data.append(trace)
                count = count+topn

    trace_input = go.Scatter3d(
                    x = three_dim[count:,0], 
                    y = three_dim[count:,1],  
                    z = three_dim[count:,2],
                    text = words[count:],
                    name = &#39;input words&#39;,
                    textposition = &quot;top center&quot;,
                    textfont_size = 20,
                    mode = &#39;markers+text&#39;,
                    marker = {
                        &#39;size&#39;: 10,
                        &#39;opacity&#39;: 1,
                        &#39;color&#39;: &#39;black&#39;
                    }
                    )

    # For 2D, instead of using go.Scatter3d, we need to use go.Scatter and delete the z variable.  Also, instead of using
    # variable three_dim, use the variable that we have declared earlier (e.g two_dim)
            
    data.append(trace_input)
    
# Configure the layout

    layout = go.Layout(
        margin = {&#39;l&#39;: 0, &#39;r&#39;: 0, &#39;b&#39;: 0, &#39;t&#39;: 0},
        showlegend=True,
        legend=dict(
        x=1,
        y=0.5,
        font=dict(
            family=&quot;Courier New&quot;,
            size=25,
            color=&quot;black&quot;
        )),
        font = dict(
            family = &quot; Courier New &quot;,
            size = 15),
        autosize = False,
        width = 1000,
        height = 1000
        )


    plot_figure = go.Figure(data = data, layout = layout)
    plot_figure.show()
    
display_pca_scatterplot_3D(model, user_input, similar_word, labels, color_map)</code></pre><p>T-Distributed Stochastic Neighbor Embedding (t-SNE) is another technique for dimensionality reduction, and it’s particularly well suited for the visualization of high-dimensional data sets. 
Contrary to PCA, it’s not a mathematical technique but a probabilistic one. </p><blockquote><p>“T-distributed stochastic neighbor embedding (t-SNE) minimizes the divergence between two distributions: a distribution that measures pairwise similarities of the input objects and a distribution that measures pairwise similarities of the corresponding low-dimensional points in the embedding.”</p></blockquote><pre><code class="python">import plotly
import numpy as np
import plotly.graph_objs as go
from sklearn.manifold import TSNE

def display_tsne_scatterplot_3D(model, user_input=None, words=None, label=None, color_map=None, 
                                perplexity = 0, learning_rate = 0, iteration = 0, topn=5, sample=10):

    if words == None:
        if sample &gt; 0:
            words = np.random.choice(list(model.vocab.keys()), sample)
        else:
            words = [ word for word in model.vocab ]
    
    word_vectors = np.array([model[w] for w in words])
    
    three_dim = TSNE(n_components = 3, random_state=0, perplexity = perplexity, 
                    learning_rate = learning_rate, n_iter = iteration).fit_transform(word_vectors)[:,:3]


    # For 2D, change the three_dim variable into something like two_dim like the following:
    # two_dim = TSNE(n_components = 2, random_state=0, perplexity = perplexity, 
    #                learning_rate = learning_rate, n_iter = iteration).fit_transform(word_vectors)[:,:2]

    data = []


    count = 0
    for i in range (len(user_input)):

                trace = go.Scatter3d(
                    x = three_dim[count:count+topn,0], 
                    y = three_dim[count:count+topn,1],  
                    z = three_dim[count:count+topn,2],
                    text = words[count:count+topn],
                    name = user_input[i],
                    textposition = &quot;top center&quot;,
                    textfont_size = 20,
                    mode = &#39;markers+text&#39;,
                    marker = {
                        &#39;size&#39;: 10,
                        &#39;opacity&#39;: 0.8,
                        &#39;color&#39;: 2
                    }
       
                )
                
                # For 2D, instead of using go.Scatter3d, we need to use go.Scatter and delete the z variable. Also, instead of using
                # variable three_dim, use the variable that we have declared earlier (e.g two_dim)
            
                data.append(trace)
                count = count+topn

    trace_input = go.Scatter3d(
                    x = three_dim[count:,0], 
                    y = three_dim[count:,1],  
                    z = three_dim[count:,2],
                    text = words[count:],
                    name = &#39;input words&#39;,
                    textposition = &quot;top center&quot;,
                    textfont_size = 20,
                    mode = &#39;markers+text&#39;,
                    marker = {
                        &#39;size&#39;: 10,
                        &#39;opacity&#39;: 1,
                        &#39;color&#39;: &#39;black&#39;
                    }
                    )

    # For 2D, instead of using go.Scatter3d, we need to use go.Scatter and delete the z variable.  Also, instead of using
    # variable three_dim, use the variable that we have declared earlier (e.g two_dim)
            
    data.append(trace_input)
    
# Configure the layout

    layout = go.Layout(
        margin = {&#39;l&#39;: 0, &#39;r&#39;: 0, &#39;b&#39;: 0, &#39;t&#39;: 0},
        showlegend=True,
        legend=dict(
        x=1,
        y=0.5,
        font=dict(
            family=&quot;Courier New&quot;,
            size=25,
            color=&quot;black&quot;
        )),
        font = dict(
            family = &quot; Courier New &quot;,
            size = 15),
        autosize = False,
        width = 1000,
        height = 1000
        )


    plot_figure = go.Figure(data = data, layout = layout)
    plot_figure.show()
    
display_tsne_scatterplot_3D(model, user_input, similar_word, labels, color_map, 5, 500, 10000)</code></pre><pre><code class="python">path = &#39;./glove.6B.50d.txt&#39;
glove_embeddings = {}
with open(path) as f:
    for line in f:
        try:
            line = line.split()
            glove_embeddings[line[0]] = np.array(line[1:], dtype=np.float32)
        except:
            continue</code></pre><pre><code class="python">def find_closest_embeddings(embedding):
    return sorted(glove_embeddings.keys(), key=lambda word: spatial.distance.euclidean(glove_embeddings[word], embedding))</code></pre><pre><code class="python">find_closest_embeddings(glove_embeddings[&quot;king&quot;])[:5]</code></pre><pre><code>[&#39;king&#39;, &#39;prince&#39;, &#39;queen&#39;, &#39;uncle&#39;, &#39;ii&#39;]</code></pre><pre><code class="python">print(find_closest_embeddings(glove_embeddings[&quot;twig&quot;] - glove_embeddings[&quot;branch&quot;] + glove_embeddings[&quot;hand&quot;])[:5])</code></pre><pre><code>[&#39;fingernails&#39;, &#39;toenails&#39;, &#39;stringy&#39;, &#39;peeling&#39;, &#39;shove&#39;]</code></pre><pre><code class="python">print(find_closest_embeddings(glove_embeddings[&quot;clock&quot;] - glove_embeddings[&quot;hand&quot;])[:5])</code></pre><pre><code>[&#39;2202&#39;, &#39;2224&#39;, &#39;20:20&#39;, &#39;3030&#39;, &#39;23:59&#39;]</code></pre></section>
  </body>
</html>
